# repositories/file_repository/file_repository.py
import os
import uuid
import hashlib
import PyPDF2
from datetime import datetime
from typing import List, Optional, Dict, Any, Tuple
from werkzeug.utils import secure_filename
from PIL import Image
import io
from sqlalchemy import func, desc, asc, or_

from models.file_upd_model import FileUpdModel
from models.contract_model import ContractModel  # å¯¼å…¥åˆåŒæ¨¡å‹
from ..base_repository import BaseRepository
from utils.file_utils import allowed_file, format_file_size
from utils.time_utils import beijing_time

class FileRepository(BaseRepository[FileUpdModel]):
    """æ–‡ä»¶ä»“å‚¨ç±» - åŒ…å«æ–‡ä»¶å¤„ç†å’Œæ•°æ®è®¿é—®é€»è¾‘"""
    
    def __init__(self, db, config=None):
        super().__init__(FileUpdModel, db)
        self.config = config or {}
    
    def validate_upload(self, file, file_type: str) -> Tuple[bool, str]:
        """éªŒè¯ä¸Šä¼ æ–‡ä»¶ - Repositoryå±‚éªŒè¯"""
        if not file or file.filename == '':
            return False, 'æ–‡ä»¶ä¸èƒ½ä¸ºç©º'
        
        if not allowed_file(file.filename, file_type, self.config):
            allowed_exts = self.config.get('ALLOWED_EXTENSIONS', {}).get(file_type, [])
            return False, f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚{file_type}ç±»å‹æ”¯æŒ: {", ".join(allowed_exts)}'
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
        file_size = file.tell()
        file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        
        max_size = self.config.get('MAX_CONTENT_LENGTH', 100 * 1024 * 1024)
        if file_size > max_size:
            return False, f'æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡ {format_file_size(max_size)}'
        
        return True, 'éªŒè¯é€šè¿‡'
    
    def save_uploaded_file(self, file, file_type: str, original_name: str = None, 
                          company_id: str = None, contract_data: Dict = None) -> Dict:
        """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ - å®Œæ•´çš„æ–‡ä»¶å¤„ç†é€»è¾‘"""
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename = secure_filename(file.filename)
        original_name = original_name or filename
        
        file_ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else ''
        unique_filename = f"{uuid.uuid4().hex}.{file_ext}" if file_ext else str(uuid.uuid4().hex)
        
        # åˆ›å»ºå­˜å‚¨ç›®å½•
        type_folder = self._get_type_folder(file_type)
        upload_path = os.path.join(self.config.get('UPLOAD_FOLDER', 'uploads'), type_folder)
        
        if not os.path.exists(upload_path):
            os.makedirs(upload_path)
        
        # ä¿å­˜ç‰©ç†æ–‡ä»¶
        file_path = os.path.join(upload_path, unique_filename)
        file.save(file_path)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        file.seek(0)
        file_data = file.read()
        file_size = len(file_data)
        mime_type = file.content_type
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = hashlib.sha256(file_data).hexdigest()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ–‡ä»¶
        existing_files = self.filter_by(file_hash=file_hash)
        # if existing_files:
        #     print(f"æ–‡ä»¶å·²å­˜åœ¨: {existing_files[0].original_name}")
            # å¯ä»¥é€‰æ‹©è·³è¿‡ä¿å­˜æˆ–åˆ›å»ºå¼•ç”¨
        
        # æå–æ–‡ä»¶å…ƒæ•°æ®
        metadata = self._extract_file_metadata(file_data, filename, mime_type)
        
        # æå–æ–‡æœ¬å†…å®¹
        text_content = self._extract_text_content(file_data, filename, mime_type)

        # ä¸Šä¼ æ—¶é—´ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
        beijing_time = self.get_beijing_time()
        
        # åˆ›å»ºæ–‡ä»¶æ•°æ®åº“è®°å½•
        file_record = self.create(
            company_id=company_id,
            original_name=original_name,
            stored_name=unique_filename,
            file_type=file_type,
            file_size=file_size,
            file_path=file_path,
            mime_type=mime_type,
            file_content=file_data,
            file_hash=file_hash,
            page_count=metadata.get('page_count'),
            text_content=text_content,
            has_ocr=metadata.get('has_ocr', False),
            ocr_confidence=metadata.get('ocr_confidence', 0.0),
            upload_time=beijing_time
        )
        
        result = {
            'file': file_record.to_response_dict()
        }

        print(f"æ–‡ä»¶ç±»å‹: {file_type},æ–‡ä»¶å†…å®¹:{contract_data}")
        
        # å¦‚æœæ˜¯åˆåŒæ–‡ä»¶ï¼ŒåŒæ—¶åˆ›å»ºåˆåŒè®°å½•
        if file_type == "1":  # "1"ä»£è¡¨åˆåŒç±»å‹:
            print(f"æ–‡ä»¶ç±»å‹2: {file_type}")
            contract_info = self._create_contract_record(file_record,company_id)
            result['contract'] = contract_info
        
        return result
    
    def _create_contract_record(self, file_record,company_id: str) :
        """åˆ›å»ºåˆåŒè®°å½•"""
        try:
            # å‡†å¤‡åˆåŒæ•°æ®
            contract_defaults = {
                'file_id': file_record.id,  # ä½¿ç”¨ file_upd çš„ id
                'company_id': company_id,
                # 'file_path': file_record.file_path,
                # 'file_name': file_record.original_name,
                # 'contract_title': contract_data.get('contract_title') or file_record.original_name.split('.')[0],
                # 'contract_amount': contract_data.get('contract_amount', 0.00),
                # 'paid_amount': contract_data.get('paid_amount', 0.00),
                # 'start_date': contract_data.get('start_date'),
                # 'end_date': contract_data.get('end_date'),
                # 'final_payment_date': contract_data.get('final_payment_date'),
                # 'final_payment_amount': contract_data.get('final_payment_amount'),
                # 'main_content': contract_data.get('main_content') or file_record.text_content or '',
                # 'memo': contract_data.get('memo', ''),
                # 'status': contract_data.get('status', 'active')
            }
            print(f"åˆ›å»ºåˆåŒè®°å½•: {contract_defaults}")
            # åˆ›å»ºåˆåŒè®°å½•
            contract = ContractModel(**contract_defaults)

            print(f"åˆ›å»ºåˆåŒè®°å½•2: {contract_defaults}")
            
            # ä½¿ç”¨å½“å‰ session
            if hasattr(self, 'session'):
                self.session.add(contract)
                self.session.commit()
            else:
                # å¦‚æœæ²¡æœ‰ sessionï¼Œä½¿ç”¨ db.session
                from .. import db
                db.session.add(contract)
                db.session.commit()
            
            return contract.to_response_dict()
            
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æ–‡ä»¶ä¿å­˜
            print(f"åˆ›å»ºåˆåŒè®°å½•å¤±è´¥: {str(e)}")
            return None
    
    def get_beijing_time(self):
        """è·å–åŒ—äº¬æ—¶é—´å€¼"""
        from utils.time_utils import beijing_time
        return beijing_time()  # ğŸŒŸ æ³¨æ„ï¼šè°ƒç”¨å‡½æ•°
    
    def _get_type_folder(self, file_type: str) -> str:
        """æ ¹æ®æ–‡ä»¶ç±»å‹è·å–å­˜å‚¨æ–‡ä»¶å¤¹"""
        type_folders = {
            'åˆåŒ': 'contracts',
            'å›¾çº¸': 'designs'
        }
        return type_folders.get(file_type, 'others')
    
    def _extract_file_metadata(self, file_data: bytes, filename: str, mime_type: str) -> Dict:
        """æå–æ–‡ä»¶å…ƒæ•°æ®"""
        metadata = {'page_count': None, 'has_ocr': False, 'ocr_confidence': 0.0}
        
        try:
            # å¤„ç†PDFæ–‡ä»¶
            if mime_type == 'application/pdf' or filename.lower().endswith('.pdf'):
                metadata.update(self._extract_pdf_metadata(file_data))
            # å¤„ç†å›¾ç‰‡æ–‡ä»¶
            elif mime_type.startswith('image/'):
                metadata.update(self._extract_image_metadata(file_data))
        except Exception as e:
            # print(f"æå–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {e}")
            pass
        
        return metadata
    
    def _extract_pdf_metadata(self, file_data: bytes) -> Dict:
        """æå–PDFæ–‡ä»¶å…ƒæ•°æ®"""
        metadata = {'page_count': 0}
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_data))
            metadata['page_count'] = len(pdf_reader.pages)
        except Exception as e:
            # print(f"æå–PDFå…ƒæ•°æ®å¤±è´¥: {e}")
            pass
        return metadata
    
    def _extract_image_metadata(self, file_data: bytes) -> Dict:
        """æå–å›¾ç‰‡å…ƒæ•°æ®"""
        metadata = {}
        try:
            image = Image.open(io.BytesIO(file_data))
            metadata['image_width'] = image.width
            metadata['image_height'] = image.height
        except Exception as e:
            # print(f"æå–å›¾ç‰‡å…ƒæ•°æ®å¤±è´¥: {e}")
            pass
        return metadata
    
    def _extract_text_content(self, file_data: bytes, filename: str, mime_type: str) -> Optional[str]:
        """æå–æ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹"""
        try:
            if mime_type == 'application/pdf' or filename.lower().endswith('.pdf'):
                return self._extract_pdf_text(file_data)
            elif mime_type.startswith('image/'):
                return self._extract_image_text(file_data)
        except Exception as e:
            # print(f"æå–æ–‡æœ¬å†…å®¹å¤±è´¥: {e}")
            pass
        return None
    
    def _extract_pdf_text(self, file_data: bytes) -> Optional[str]:
        """ä»PDFæå–æ–‡æœ¬"""
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_data))
            text_content = []
            for page_num, page in enumerate(pdf_reader.pages, 1):
                try:
                    page_text = page.extract_text()
                    if page_text.strip():
                        text_content.append(page_text)
                except:
                    continue
            return "\n\n".join(text_content) if text_content else None
        except Exception as e:
            # print(f"æå–PDFæ–‡æœ¬å¤±è´¥: {e}")
            return None
    
    def _extract_image_text(self, file_data: bytes) -> Optional[str]:
        """ä»å›¾ç‰‡æå–æ–‡æœ¬ï¼ˆOCRï¼‰"""
        try:
            import pytesseract
            image = Image.open(io.BytesIO(file_data))
            text = pytesseract.image_to_string(image, lang='chi_sim+eng')
            return text if text.strip() else None
        except ImportError:
            # print("pytesseractæœªå®‰è£…ï¼Œè·³è¿‡OCR")
            return None
        except Exception as e:
            # print(f"å›¾ç‰‡OCRå¤±è´¥: {e}")
            return None
    
    def get_by_filename(self, filename: str) -> Optional[FileUpdModel]:
        """æ ¹æ®æ–‡ä»¶åè·å–æ–‡ä»¶"""
        return self.session.query(FileUpdModel).filter_by(stored_name=filename).first()
    
    def get_by_file_type(self, file_type: str) -> List[FileUpdModel]:
        """æ ¹æ®æ–‡ä»¶ç±»å‹è·å–æ–‡ä»¶åˆ—è¡¨"""
        return self.filter_by(file_type=file_type)
    
    def get_recent_files(self, limit: int = 10) -> List[FileUpdModel]:
        """è·å–æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶"""
        return self.session.query(FileUpdModel)\
            .order_by(desc(FileUpdModel.upload_time))\
            .limit(limit)\
            .all()
    
    def get_file_stats(self) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        # æ€»æ–‡ä»¶æ•°
        total_count = self.session.query(func.count(FileUpdModel.id)).scalar()
        stats['total_files'] = total_count
        
        # æ€»æ–‡ä»¶å¤§å°
        total_size = self.session.query(func.sum(FileUpdModel.file_size)).scalar() or 0
        stats['total_size'] = total_size
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_stats = self.session.query(
            FileUpdModel.file_type,
            func.count(FileUpdModel.id).label('count'),
            func.sum(FileUpdModel.file_size).label('size')
        ).group_by(FileUpdModel.file_type).all()
        stats['by_type'] = [
            {
                'file_type': result.file_type,
                'count': result.count,
                'size': result.size or 0
            }
            for result in type_stats
        ]
        return stats
    
    def search_files(self, keyword: str, file_type: str = None) -> List[FileUpdModel]:
        """æœç´¢æ–‡ä»¶"""
        query = self.session.query(FileUpdModel)
        
        # åœ¨å¤šä¸ªå­—æ®µä¸­æœç´¢
        if keyword:
            search_conditions = []
            search_fields = ['original_name']
            
            for field in search_fields:
                if hasattr(FileUpdModel, field):
                    field_attr = getattr(FileUpdModel, field)
                    search_conditions.append(field_attr.ilike(f'%{keyword}%'))
            
            if search_conditions:
                query = query.filter(or_(*search_conditions))
        
        # æŒ‰ç±»å‹è¿‡æ»¤
        if file_type:
            query = query.filter_by(file_type=file_type)
        
        return query.all()
    
    def delete_file_with_physical(self, file_id: str) -> bool:
        """åˆ é™¤æ–‡ä»¶ï¼ˆåŒ…å«ç‰©ç†æ–‡ä»¶ï¼‰"""
        try:
            file = self.get_by_id(file_id)
            if not file:
                return False
            
            # å¦‚æœæ˜¯åˆåŒæ–‡ä»¶ï¼ŒåŒæ—¶åˆ é™¤åˆåŒè®°å½•
            if file.file_type == 'åˆåŒ':
                contract = self.session.query(ContractModel).filter_by(
                    file_path=file.file_path
                ).first()
                if contract:
                    self.session.delete(contract)
            
            # åˆ é™¤ç‰©ç†æ–‡ä»¶
            if os.path.exists(file.file_path):
                try:
                    os.remove(file.file_path)
                except OSError as e:
                    # print(f"åˆ é™¤ç‰©ç†æ–‡ä»¶å¤±è´¥: {e}")
                    pass
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            return self.delete(file_id)
            
        except Exception as e:
            # print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def batch_delete_files(self, file_ids: List[str]) -> Dict[str, List]:
        """æ‰¹é‡åˆ é™¤æ–‡ä»¶"""
        results = {'deleted': [], 'failed': []}
        
        for file_id in file_ids:
            try:
                if self.delete_file_with_physical(file_id):
                    results['deleted'].append(file_id)
                else:
                    results['failed'].append({
                        'file_id': file_id,
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                    })
            except Exception as e:
                results['failed'].append({
                    'file_id': file_id,
                    'error': str(e)
                })
        
        return results

    def batch_upload_files(self, files, file_type: str, company_id: str = None, 
                          contract_data_list: List[Dict] = None) -> Dict[str, List]:
        """æ‰¹é‡ä¸Šä¼ æ–‡ä»¶"""
        results = {'success': [], 'failed': []}
        
        contract_data_list = contract_data_list or []
        
        for i, file in enumerate(files):
            try:
                # éªŒè¯æ–‡ä»¶
                is_valid, message = self.validate_upload(file, file_type)
                if not is_valid:
                    results['failed'].append({
                        'filename': file.filename,
                        'error': message
                    })
                    continue
                
                # è·å–å¯¹åº”çš„åˆåŒæ•°æ®
                contract_data = contract_data_list[i] if i < len(contract_data_list) else None

                # print(f" åˆåŒæ•°æ®: {contract_data}")
                
                # ä¿å­˜æ–‡ä»¶
                file_info = self.save_uploaded_file(
                    file=file, 
                    file_type=file_type,
                    company_id=company_id,
                    contract_data=contract_data
                )
                results['success'].append(file_info)
                
            except Exception as e:
                results['failed'].append({
                    'filename': file.filename,
                    'error': str(e)
                })
        
        return results
    
    def get_file_content(self, file_id: str) -> Optional[bytes]:
        """è·å–æ–‡ä»¶å†…å®¹"""
        try:
            file = self.get_by_id(file_id)
            if file and file.file_content:
                return file.file_content
        except Exception as e:
            # print(f"è·å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            pass
        return None
    
    def get_paginated_files(self, page=1, page_size=10, file_type=None, keyword=None, company_id=None):
        """è·å–åˆ†é¡µæ–‡ä»¶åˆ—è¡¨"""
        try:
            
            # ç¡®ä¿ self.session å­˜åœ¨
            if not hasattr(self, 'session'):
                # å°è¯•ä»çˆ¶ç±»è·å–
                if hasattr(self, 'db') and hasattr(self.db, 'session'):
                    self.session = self.db.session
                elif hasattr(self, 'db') and hasattr(self.db, 'query'):
                    # å¦‚æœ self.db æœ¬èº«å°±æ˜¯ session
                    self.session = self.db
                else:
                    raise AttributeError("æ— æ³•è·å–æ•°æ®åº“ session")
            
            query = self.session.query(FileUpdModel)
            
            # åº”ç”¨ç±»å‹è¿‡æ»¤
            if file_type:
                query = query.filter(FileUpdModel.file_type == file_type)

            # åº”ç”¨å…¬å¸IDè¿‡æ»¤
            if company_id and company_id != "all":
                query = query.filter(FileUpdModel.company_id == company_id)
            
            # åº”ç”¨å…³é”®å­—æœç´¢
            if keyword:
                query = query.filter(
                    (FileUpdModel.original_name.ilike(f'%{keyword}%')) 
                )
            
            # è®¡ç®—æ€»æ•°
            total = query.count()
            
            # è®¡ç®—åˆ†é¡µ
            total_pages = (total + page_size - 1) // page_size
            offset = (page - 1) * page_size
            
            # è·å–å½“å‰é¡µæ•°æ®
            query = query.order_by(FileUpdModel.upload_time.desc())
            files = query.offset(offset).limit(page_size).all()

            return {
                'items': files,
                'total': total,
                'page': page,
                'pageSize': page_size,
                'totalPages': total_pages
            }
            
        except Exception as e:
            self.logger.error(f"è·å–åˆ†é¡µæ–‡ä»¶åˆ—è¡¨é”™è¯¯: {str(e)}")
            raise
    
    def get_contract_by_file_id(self, file_id: str) -> Optional[Dict]:
        """æ ¹æ®æ–‡ä»¶IDè·å–å…³è”çš„åˆåŒä¿¡æ¯"""
        try:
            file = self.get_by_id(file_id)
            if not file or file.file_type != 'åˆåŒ':
                return None
            
            contract = self.session.query(ContractModel).filter_by(
                file_path=file.file_path
            ).first()
            
            if contract:
                return contract.to_response_dict()
            return None
            
        except Exception as e:
            print(f"è·å–åˆåŒä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def get_by_company_id(self, company_id: str, file_type: str = None) -> List[FileUpdModel]:
        """æ ¹æ®å®¢æˆ·IDè·å–æ–‡ä»¶åˆ—è¡¨"""
        try:
            query = self.session.query(FileUpdModel).filter_by(company_id=company_id)
            
            if file_type:
                query = query.filter_by(file_type=file_type)
            
            return query.order_by(desc(FileUpdModel.upload_time)).all()
        except Exception as e:
            if hasattr(self, 'logger') and self.logger:
                self.logger.error(f'è·å–å…¬å¸æ–‡ä»¶åˆ—è¡¨å¤±è´¥ company_id={company_id}: {e}')
            return []
    
    def search_files(self, keyword: str, file_type: str = None, company_id: str = None) -> List[FileUpdModel]:
        """æœç´¢æ–‡ä»¶"""
        try:
            query = self.session.query(FileUpdModel)
            
            # åº”ç”¨å…¬å¸IDè¿‡æ»¤
            if company_id:
                query = query.filter(FileUpdModel.company_id == company_id)
            
            # åº”ç”¨ç±»å‹è¿‡æ»¤
            if file_type:
                query = query.filter(FileUpdModel.file_type == file_type)
            
            # å…³é”®å­—æœç´¢
            if keyword and keyword.strip():
                search_conditions = []
                search_fields = ['original_name', 'text_content']
                
                for field in search_fields:
                    if hasattr(FileUpdModel, field):
                        field_attr = getattr(FileUpdModel, field)
                        search_conditions.append(field_attr.ilike(f'%{keyword}%'))
                
                if search_conditions:
                    query = query.filter(or_(*search_conditions))
            
            return query.order_by(desc(FileUpdModel.upload_time)).all()
            
        except Exception as e:
            if hasattr(self, 'logger') and self.logger:
                self.logger.error(f'æœç´¢æ–‡ä»¶å¤±è´¥ keyword={keyword}: {e}')
            return []